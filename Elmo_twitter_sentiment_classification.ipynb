{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of ELMo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset \n",
    "\n",
    "2. Tweets from pages of different mobile companies \n",
    "\n",
    "Here’s a breakdown of the dataset we have:\n",
    "\n",
    "The train set contains 7,920 tweets\n",
    "The test set contains 1,953 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------- Imports ------------------------\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_for_elmo/train_2kmZucJ.csv\")\n",
    "test = pd.read_csv(\"data_for_elmo/test_oJQbWVk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      1   \n",
       "\n",
       "                                                                                                                                 tweet  \n",
       "0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone  \n",
       "1  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/  \n",
       "2          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu  \n",
       "3                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/  \n",
       "4         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7920, 3), (1953, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27027c37448>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 1 represents a negative tweet while 0 represents a non-negative tweet.\n",
    "\n",
    "Let’s take a quick look at the first 5 rows in our train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.744192\n",
       "1    0.255808\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be quite a few URL links in the tweets. They are not telling us much (if anything) about the sentiment of the tweet so let’s remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove URL's from train and test\n",
    "train['clean_tweet'] = train['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "test['clean_tweet'] = test['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used Regular Expressions (or RegEx) to remove the URLs.\n",
    "\n",
    "Note: You can learn more about Regex in this article.\n",
    "\n",
    "We’ll go ahead and do some routine text cleaning now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "train['clean_tweet'] = train['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "\n",
    "# convert text to lowercase\n",
    "train['clean_tweet'] = train['clean_tweet'].str.lower()\n",
    "test['clean_tweet'] = test['clean_tweet'].str.lower()\n",
    "\n",
    "# remove numbers\n",
    "train['clean_tweet'] = train['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "test['clean_tweet'] = test['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
    "\n",
    "# remove whitespaces\n",
    "train['clean_tweet'] = train['clean_tweet'].apply(lambda x:' '.join(x.split()))\n",
    "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will lemmatize (normalize) the text by leveraging the popular spaCy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spaCy's language model\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_tweet'] = lemmatization(train['clean_tweet'])\n",
    "test['clean_tweet'] = lemmatization(test['clean_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7125</td>\n",
       "      <td>7126</td>\n",
       "      <td>0</td>\n",
       "      <td>#bday to ME! Bought myself a new #backpack for my #camera #gear #microphone #sony #mylife… http://instagram.com/p/Y0RW_8MzJz/</td>\n",
       "      <td>bday to -PRON- buy -PRON- a new backpack for -PRON- camera gear microphone sony mylife …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>Photo: #iphonesia, #iphone, #instagood, #instagram, #photooftheday, #tweegram, , #iphoneonly, #igers,... http://tmblr.co/ZZ7XpxPqMwKt</td>\n",
       "      <td>photo iphonesia , iphone , instagood , instagram , photooftheday , tweegram , , iphoneonly , iger , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok let's go #sony #z1 #paixaodecristo #rec #hdv #equipedelta #eita #aovivo #pacatuba #gravação… http://instagram.com/p/m-R4wsFyqK/</td>\n",
       "      <td>ok let -PRON- go sony z paixaodecristo rec hdv equipedelta eita aovivo pacatuba gravação …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4476</td>\n",
       "      <td>4477</td>\n",
       "      <td>0</td>\n",
       "      <td>Fim de boat!!!!!! #iphone #girl #valescapopozuda #now #nice @ Fenix Party http://instagram.com/p/c3i8KHnR1B/</td>\n",
       "      <td>fim de boat iphone girl valescapopozuda now nice fenix party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6802</td>\n",
       "      <td>6803</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm so #wasted I almost drop my #iPhone 4!!! That would've made me #cry!! I know it sounds #pathetic but I just my</td>\n",
       "      <td>-PRON- be so waste i almost drop -PRON- iphone that would have make -PRON- cry i know -PRON- sound pathetic but i just -PRON-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3085</td>\n",
       "      <td>3086</td>\n",
       "      <td>0</td>\n",
       "      <td>My sis @wtfxdaryl, my bro, and I #sibling #sis #bro #holidays #2011 #life #like #iphonesia #iphone http://instagr.am/p/cZZIC/</td>\n",
       "      <td>-PRON- sis wtfxdaryl , -PRON- bro , and i sible sis bro holiday life like iphonesia iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5889</td>\n",
       "      <td>5890</td>\n",
       "      <td>0</td>\n",
       "      <td>#California HD Wallpapers now in #Appstore #CaliforniaDreaming #CaliforniaGirl #iPhoneWallpaper https://itunes.apple.com/app/id1033024421 … #IPhone</td>\n",
       "      <td>california hd wallpaper now in appstore californiadreame californiagirl iphonewallpaper … iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6343</td>\n",
       "      <td>6344</td>\n",
       "      <td>0</td>\n",
       "      <td>Ready to rock. #film #sony #work #afterhours #army #armygirl #nurse #military #bts https://instagram.com/p/7E1eRGJHph/</td>\n",
       "      <td>ready to rock . film sony work afterhours army armygirl nurse military bts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2436</td>\n",
       "      <td>2437</td>\n",
       "      <td>1</td>\n",
       "      <td>I literally got the iPhone 6 YESTERDAY and it already sucks. #goiphone #apple</td>\n",
       "      <td>i literally get the iphone yesterday and -PRON- already suck . goiphone apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2322</td>\n",
       "      <td>2323</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy birthday to me. #sonystudios #sony #film #movie #hbd birthday #birthday … https://instagram.com/p/0dpfYZP4aU/</td>\n",
       "      <td>happy birthday to -PRON- . sonystudios sony film movie hbd birthday birthday …</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label  \\\n",
       "7125  7126      0   \n",
       "333    334      0   \n",
       "840    841      0   \n",
       "4476  4477      0   \n",
       "6802  6803      0   \n",
       "3085  3086      0   \n",
       "5889  5890      0   \n",
       "6343  6344      0   \n",
       "2436  2437      1   \n",
       "2322  2323      0   \n",
       "\n",
       "                                                                                                                                                    tweet  \\\n",
       "7125                        #bday to ME! Bought myself a new #backpack for my #camera #gear #microphone #sony #mylife… http://instagram.com/p/Y0RW_8MzJz/   \n",
       "333                 Photo: #iphonesia, #iphone, #instagood, #instagram, #photooftheday, #tweegram, , #iphoneonly, #igers,... http://tmblr.co/ZZ7XpxPqMwKt   \n",
       "840                    Ok let's go #sony #z1 #paixaodecristo #rec #hdv #equipedelta #eita #aovivo #pacatuba #gravação… http://instagram.com/p/m-R4wsFyqK/   \n",
       "4476                                         Fim de boat!!!!!! #iphone #girl #valescapopozuda #now #nice @ Fenix Party http://instagram.com/p/c3i8KHnR1B/   \n",
       "6802                                   I'm so #wasted I almost drop my #iPhone 4!!! That would've made me #cry!! I know it sounds #pathetic but I just my   \n",
       "3085                        My sis @wtfxdaryl, my bro, and I #sibling #sis #bro #holidays #2011 #life #like #iphonesia #iphone http://instagr.am/p/cZZIC/   \n",
       "5889  #California HD Wallpapers now in #Appstore #CaliforniaDreaming #CaliforniaGirl #iPhoneWallpaper https://itunes.apple.com/app/id1033024421 … #IPhone   \n",
       "6343                               Ready to rock. #film #sony #work #afterhours #army #armygirl #nurse #military #bts https://instagram.com/p/7E1eRGJHph/   \n",
       "2436                                                                        I literally got the iPhone 6 YESTERDAY and it already sucks. #goiphone #apple   \n",
       "2322                                  Happy birthday to me. #sonystudios #sony #film #movie #hbd birthday #birthday … https://instagram.com/p/0dpfYZP4aU/   \n",
       "\n",
       "                                                                                                                        clean_tweet  \n",
       "7125                                       bday to -PRON- buy -PRON- a new backpack for -PRON- camera gear microphone sony mylife …  \n",
       "333                         photo iphonesia , iphone , instagood , instagram , photooftheday , tweegram , , iphoneonly , iger , ...  \n",
       "840                                      ok let -PRON- go sony z paixaodecristo rec hdv equipedelta eita aovivo pacatuba gravação …  \n",
       "4476                                                                   fim de boat iphone girl valescapopozuda now nice fenix party  \n",
       "6802  -PRON- be so waste i almost drop -PRON- iphone that would have make -PRON- cry i know -PRON- sound pathetic but i just -PRON-  \n",
       "3085                                     -PRON- sis wtfxdaryl , -PRON- bro , and i sible sis bro holiday life like iphonesia iphone  \n",
       "5889                               california hd wallpaper now in appstore californiadreame californiagirl iphonewallpaper … iphone  \n",
       "6343                                                     ready to rock . film sony work afterhours army armygirl nurse military bts  \n",
       "2436                                                  i literally get the iphone yesterday and -PRON- already suck . goiphone apple  \n",
       "2322                                                 happy birthday to -PRON- . sonystudios sony film movie hbd birthday birthday …  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable v2 behaviour of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "elmo = hub.Module(\"C:\\\\Users\\\\mpspa\\\\Desktop\\\\purdue\\\\assignments\\\\NLP\\\\data_for_elmo\\\\elmo_2.tar\", trainable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will first show you how we can get ELMo vectors for a sentence. All you have to do is pass a list of string(s) in the object elmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 8, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = elmo(x,  signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output is a 3 dimensional tensor of shape (1, 8, 1024):\n",
    "\n",
    "- The first dimension of this tensor represents the number of training samples. This is 1 in our case\n",
    "- The second dimension represents the maximum length of the longest string in the input list of strings. Since we have only 1 string in our input list, the size of the 2nd dimension is equal to the length of the string – 8\n",
    "- The third dimension is equal to the length of the ELMo vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    # return average of ELMo features\n",
    "    return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]\n",
    "list_test = [test[i:i+100] for i in range(0,test.shape[0],100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_train = [elmo_vectors(x['clean_tweet']) for x in list_train]\n",
    "elmo_test = [elmo_vectors(x['clean_tweet']) for x in list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
    "elmo_test_new = np.concatenate(elmo_test, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save elmo_train_new\n",
    "pickle_out = open(\"data_for_elmo\\\\elmo_train_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_train_new, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# save elmo_test_new\n",
    "pickle_out = open(\"data_for_elmo\\\\elmo_test_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_test_new, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elmo_train_new\n",
    "pickle_in = open(\"data_for_elmo\\\\elmo_train_03032019.pickle\", \"rb\")\n",
    "elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "# load elmo_train_new\n",
    "pickle_in = open(\"data_for_elmo\\\\elmo_test_03032019.pickle\", \"rb\")\n",
    "elmo_test_new = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n",
    "                                                  train['label'],  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = lreg.predict(xvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, precision_recall_curve,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.875\n",
      "precision :  0.7910447761194029\n",
      "recall :  0.7361111111111112\n",
      "f1 score :  0.7625899280575541\n",
      "confusion :  [[1068   84]\n",
      " [ 114  318]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \", accuracy_score(yvalid, preds_valid))\n",
    "print(\"precision : \", precision_score(yvalid, preds_valid))\n",
    "print(\"recall : \", recall_score(yvalid, preds_valid))\n",
    "print(\"f1 score : \", f1_score(yvalid, preds_valid))\n",
    "print(\"confusion : \", confusion_matrix(yvalid, preds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
